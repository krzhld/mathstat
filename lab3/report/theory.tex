\section{Теория}

\subsection{Представление данных}
В первую очередь представим данные таким образом, чтобы применить понятия статистики данных с интервальной неопределенностью.
Один из распространённых способов получения интервальных результатов в первичных измерениях -- это <<обинтерваливание>> точечных значений, когда к точечному базовому зачению $\dot x$, которое считывается по показаниям измерительного прибора, прибавляется
\textit{интервал погрешности} $\varepsilon$:
\begin{equation}
	\textbf{x}=\dot {x}+ \mathbf{\varepsilon}
\end{equation}

Интервал погрешности зададим как
\begin{equation*}
	\mathbf{\varepsilon}=[-\xi;\xi]
\end{equation*}

В конкретных измерениях примем $\xi$ = $10^{-4}$ мВ. \\
Согласно терминологии интервального анализа, рассматриваемая выборка -- это вектор интервалов, или интервальный вектор $x=(x_1, x_2, ..., x_n)$. \\
Информационным множеством в случае оценивания единичной физической величины по выборке интервальных данных будет тaкжe интервал, который называют информационным интервалом. Неформально говоря, это интервал, содержащий значения оцениваемой величины, которые <<совместны>> с измерениями выборки (<<согласуются>> с данными этих измерений).



\subsection{Линейная регрессия}

\subsubsection{Описание модели}
Регрессионную модель описания данных называют простой линейной, если заданный набор данных аппроксимируется прямой с внесённой добавкой в виде некоторой нормально распределенной ошибки:

\begin{equation}
	y_i = \beta_0 + \beta_1*x_i + \varepsilon_i, i \in \overline{1,n}
\end{equation}
где \\
$\{x_i\}_{i=1}^n$ -- заданные значения, \\
$\{y_i\}_{i=1}^n$ -- параметры отклика, \\
$\{\varepsilon_i\}_{i=1}^n$ -- независимые, центрированные, нормально распределённые случайные величины с неизвестной дисперсией $\delta$, суть предполагаемые погрешности, \\
$\beta_0, \beta_1$ -- параметры, подлежащие оцениванию. \\

В данной модели мы считаем, что у заданных значений нет погрешности (пренебрегаем ей). Считаем, что основная погрешность получается при измерении $y_i$.


\subsubsection{Метод наименьших модулей}
Для наиболее точного приближения входных с фотоприемников данных $y_i$ аппроксимирующей функции  $f(x_i)$ используется метод наименьших модулей. Этот метод основывается на минимизации $l^1$-нормы разности последовательностей:
\begin{equation}
	\| f(x_i) - y_i\|_{l^1} \rightarrow min
\end{equation}

В данном случае ставится задача линейного программирования, решение которой дает нам коэффициенты $\beta_0$ и $\beta_1$, а также вектор множителей коррекции данных $w$, на который стоит домножить погрешности наших интервальных данных. \\
По итогу получается следующая задача линейного программирования:
\begin{equation}
	\sum_{i=1}^n w_i \rightarrow min
\end{equation} \label{eq:mnm}
При ограничениях:
\begin{equation}
	\beta_0 + \beta_1*x_i - w_i * \xi \leq y_i, i \in \overline{1,n}
\end{equation}
\begin{equation}
	\beta_0 + \beta_1*x_i + w_i * \xi \geq y_i, i \in \overline{1,n}
\end{equation}
\begin{equation}
	w_i \geq 1, i \in \overline{1,n}
\end{equation}



\subsection{Предварительная обработка данных}
Из последующих результатов ясно, что для оценки коэффициента калибровки необходима предварительная обработка данных. Для этого можем задаться линейной моделью дрейфа.
\begin{equation}
	Lin(n) = A + B \cdot n, n \in \overline{1,N},
\end{equation}

Поставив задачу линейного программирования, воспользуемся методом наименьших модулей \eqref{eq:mnm} и найдем коэффициенты $A_$, $i$ и вектор $w$ множителей коррекции данных для каждого из фотоприемников ФП1 и ФП2. \\
Для данных с первого фотоприемника: $A = 4.748, B = 9.173 \cdot 10^{-6}$ \\
Для данных со второго фотоприемника: $A = 5.182, B = 1.105 \cdot 10^{-5}$ \\
В последствии множитель коррекции данных необходимо применить к погрешностям выборки, чтобы получить данные, которые согласовывались с линейной моделью дрейфа:
\begin{equation}
	I^f(n) = \dot{x}(n) + \varepsilon \cdot w(n), n \in \overline{1,N}
\end{equation}

В итоге необходимо построить <<спрямленные>> данные выборки: получить их можно путем вычитания из исходных данных линейную компоненту:
\begin{equation}
	I^c(n) = I^f(n) - B \cdot n, n \in \overline{1,N}
\end{equation}



\subsection{Коэффициент Жаккара}
В различных областях анализа данных в науках о Зeмлe, биологии, информатике используют множество мер сходства множеств. Иначе их называют коэффициентами сходства. Нами рассматривается модификация индекса Жаккара для интервальных данных:
\begin{equation} \label{eq:JK}
	JK(x) = \frac{wid(\wedge x_i)}{wid(\vee x_i)} 
\end{equation} 

В качестве меры рассматривается ширина интервала, а вместо операций пересечения и объединения -- операции взятия минимума и максимума по включению двух величин в интервальной арифметике (Каухера). Заметим что минимум по включению может быть неправильным интервалом, а значит данный коэффициент будет нормирован в отрезке $[-1,1]$.



\subsection{Процедура оптимизации}
Чтобы найти оптимальный параметр калибровки $R_{21}$ \eqref{eq:task} необходимо поставить и решить задачу максимизации коэффициента Жаккара, зависящего от параметра калибровки:
\begin{equation}
	JK(x_{all}(R)) \rightarrow max,
\end{equation}
где $JK$ -- это коэффициент Жаккара \eqref{eq:JK}, $x_{all}$ -- это выборка, полученная как
\begin{equation}
	x_{all}(R) = I_1^c \cdot R \cup I_2^c,
\end{equation}
т.е. конкатенация полученных спрямлённых выборок $I_1^c$ и $I_2^c$, последняя из которых домножена на $R$ -- параметр калибровки. Поиск оптимального $R$ будем проводить методом дихотомии в отрезке $[1;3]$. Найденный таким образом $R$ и будет искомым оптимальным $R_{21}$ в силу наибольшего совпадения, оцененного коэффицентом Жаккара.

\newpage